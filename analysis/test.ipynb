{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "150b42f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 501\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import tifffile\n",
    "\n",
    "base_path = Path('/media/sasaki/myssd/Sasaki/MTSingleBeads')\n",
    "folder = base_path / '20260122/exp001'\n",
    "tiff_path = folder / 'MTs.tif'\n",
    "\n",
    "# メモリマップモードで開く（実際にはまだデータはメモリに乗っていません）\n",
    "with tifffile.TiffFile(tiff_path) as tif:\n",
    "    # 配列のようにアクセスできるオブジェクトを取得\n",
    "    images = tif.asarray()\n",
    "    \n",
    "    print(f\"Total frames: {images.shape[0]}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b35cf125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 2, ..., 2, 1, 0],\n",
       "       [0, 1, 1, ..., 1, 0, 0],\n",
       "       [0, 1, 2, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c223dd15",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mimageio\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/opticalflow-activenematics/.pixi/envs/default/lib/python3.9/site-packages/torchvision/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodulefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/opticalflow-activenematics/.pixi/envs/default/lib/python3.9/site-packages/torchvision/_meta_registrations.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibrary\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Ensure that torch.ops.torchvision is visible\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_meta_lib\u001b[39m():\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mLibrary(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchvision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMPL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/opticalflow-activenematics/.pixi/envs/default/lib/python3.9/site-packages/torchvision/extension.py:92\u001b[0m\n\u001b[1;32m     88\u001b[0m     lib_path \u001b[38;5;241m=\u001b[39m _get_extension_path(lib_name)\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mload_library(lib_path)\n\u001b[0;32m---> 92\u001b[0m \u001b[43m_check_cuda_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/opticalflow-activenematics/.pixi/envs/default/lib/python3.9/site-packages/torchvision/extension.py:65\u001b[0m, in \u001b[0;36m_check_cuda_version\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda \u001b[38;5;28;01mas\u001b[39;00m torch_version_cuda\n\u001b[0;32m---> 65\u001b[0m _version \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _version \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m torch_version_cuda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     tv_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(_version)\n",
      "File \u001b[0;32m~/Desktop/opticalflow-activenematics/.pixi/envs/default/lib/python3.9/site-packages/torch/_ops.py:755\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;66;03m# is still callable from JIT\u001b[39;00m\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from os.path import dirname, abspath\n",
    "sys.path.insert(0, dirname(dirname(abspath(__file__))))\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import zarr\n",
    "import imageio.v2 as imageio\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from RAFT.core.raft import RAFT\n",
    "from RAFT.core.utils.utils import InputPadder\n",
    "\n",
    "\n",
    "def get_velocity(image1, image2, args):\n",
    "\n",
    "    image1 = Image.open(image1).convert('RGB')\n",
    "    image2 = Image.open(image2).convert('RGB')\n",
    "\n",
    "    image1 = transforms.ToTensor()(image1).unsqueeze(0)\n",
    "    image2 = transforms.ToTensor()(image2).unsqueeze(0)\n",
    "\n",
    "    padder = InputPadder(image1.shape, 8)\n",
    "    image1, image2 = padder.pad(image1, image2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, flow_forward = model(image1, image2, iters=args.iter, test_mode=True)\n",
    "    \n",
    "    flow_fw = padder.unpad(flow_forward).squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "   \n",
    "    return flow_fw\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # define model params\n",
    "    parser.add_argument('--model', help=\"restore checkpoint\", default='./models/weights.pth')\n",
    "    parser.add_argument('--small', action='store_true', help='use small model')\n",
    "    parser.add_argument('--mixed_precision', action='store_true', help='use mixed precision')\n",
    "    parser.add_argument('--save_location', help=\"save the results in local or oss\")\n",
    "    parser.add_argument('--save_path', help=\" local path to save the result\")\n",
    "    parser.add_argument('--iter', type=int, default=24)\n",
    "    parser.add_argument('--alpha', default=0.75)\n",
    "    parser.add_argument('--splatting', default='max')    \n",
    "    args = parser.parse_args()\n",
    "\n",
    "    \n",
    "    # load model\n",
    "    torch.cuda.empty_cache()    \n",
    "    model = torch.nn.DataParallel(RAFT(args))\n",
    "    model.load_state_dict(torch.load(args.model))    \n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    # compute a single velocity field from a pair of images\n",
    "    image1 = images[0]\n",
    "    image2 = images[1] \n",
    "    flows = get_velocity(image1, image2, args)\n",
    "    vx, vy = flows[:,:,0], flows[:,:,1]\n",
    "\n",
    "    # visualize flow field overlay on first image\n",
    "    fig, ax = plt.subplots()\n",
    "    im1 = plt.imread(image1)\n",
    "    ax.imshow(im1, cmap=\"gray\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.tight_layout()\n",
    "    n = 20  # grid size for ploting velocity vectors\n",
    "    x, y = np.meshgrid(np.arange(0, vx.shape[1], n), np.arange(0, vx.shape[0], n))\n",
    "    ax.quiver(x, y, vx[::n, ::n], vy[::n, ::n], color=\"red\", scale_units=\"xy\", angles=\"xy\", scale=0.5, width=0.001)\n",
    "    fig.savefig('./example/velocity_plot.png', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2705c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
